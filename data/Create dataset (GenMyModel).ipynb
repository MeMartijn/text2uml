{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os, json, fasttext, re\n",
    "from lxml import etree as ET\n",
    "import copy\n",
    "import unicodedata as ud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Create a flatten function\n",
    "flatten = lambda t: [item for sublist in t for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'data/repo-genmymodel-uml/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = next(os.walk(data_root), (None, None, []))[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML UML tag patterns\n",
    "\n",
    "In ed9c3064-7fb5-4ec0-bded-c114251076fa.xmi.uml, packagedElement tags are used to define classes (```uml:Class```): \n",
    "\n",
    "```\n",
    "<packagedElement xsi:type=\"uml:Class\" xmi:id=\"_eI6xoFdMEDCGTb6ZuLm3Mw\" name=\"Client\">\n",
    "```\n",
    "\n",
    "The ownedAttribute tag holds attribute names:\n",
    "\n",
    "```\n",
    "<ownedAttribute xmi:id=\"_GVIe2JUXEeqqGZh46IEtXQ\" name=\"id\">\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for patterns in files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_and_attributes_from_uml(filepath):\n",
    "    root = ET.parse(data_root + '/' + filepath)\n",
    "    \n",
    "    # Gather classes and attributes using defined patterns\n",
    "    classes = root.xpath(\"//packagedElement[@xsi:type='uml:Class']/@name\", namespaces={'xsi': 'http://www.w3.org/2001/XMLSchema-instance'})\n",
    "    attributes = root.xpath(\"//packagedElement[@xsi:type='uml:Class']/ownedAttribute/@name\", namespaces={'xsi': 'http://www.w3.org/2001/XMLSchema-instance'})\n",
    "    \n",
    "    # Save classes and attributes in list if they hold values\n",
    "    found_data = {}\n",
    "    if len(classes) > 0:\n",
    "        found_classes = [x for x in [x.strip() for x in classes] if x != '']\n",
    "        if len(found_classes) > 0:\n",
    "            found_data['classes'] = found_classes\n",
    "    if len(attributes) > 0:\n",
    "        found_attributes = [x for x in [x.strip() for x in attributes] if x != '']\n",
    "        if len(found_classes) > 0:\n",
    "            found_data['attributes'] = found_attributes\n",
    "    \n",
    "    return found_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_classes_and_attributes_from_uml('ed9c3064-7fb5-4ec0-bded-c114251076fa.xmi.uml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "\n",
    "for file in tqdm(filenames):\n",
    "    try:\n",
    "        data = get_classes_and_attributes_from_uml(file)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    if len(data.keys()) > 0:\n",
    "        data_dict[file] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in data_dict.keys():\n",
    "    if 'classes' not in data_dict[file].keys() or len(data_dict[file]['classes']) == 0:\n",
    "        print(file)\n",
    "        print(data_dict[file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total amount of unique classes\n",
    "print(len(np.unique(np.array(list(map(lambda x: x.strip(), flatten([data_dict[file]['classes'] for file in data_dict.keys()])))))))\n",
    "\n",
    "# Get total amount of unique attributes\n",
    "print(len(np.unique(np.array(flatten([[str(attr).strip() for attr in values['attributes']] for values in data_dict.values() if 'attributes' in values.keys()])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/genmymodel_uml_extracted_metadata.json', 'w') as fp:\n",
    "    json.dump(data_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First \"raw\" data cleaning cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/genmymodel_uml_extracted_metadata.json') as json_file:\n",
    "    data_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_be_kept(text):\n",
    "    # Check if larger than 1 character\n",
    "    if len(text) > 1:\n",
    "        # Remove function calls '_8Ux_QFaxEeSu48YT12vqpQ.xmi.uml'\n",
    "        if text[-2:] == '()':\n",
    "            return False\n",
    "\n",
    "        # Remove getters and setters '_UWr2cM_JEeeLcIicqHdTUQ.xmi.uml' '_va9xEFzhEeqK2M3E1LfZ7Q.xmi.uml'\n",
    "        if re.search(r'^[gs]et(?:[A-Z]|_)\\w+', text):\n",
    "            return False\n",
    "\n",
    "        # Remove dot seperated widgets/views and filenames '_tGyV0EbLEeeTJ_4Vl2J2rQ.xmi.uml' '_WZQeEMJ8EeSII650IQ0Z1w.xmi.uml'\n",
    "        if re.search(r'^\\w+\\.\\w+(?:\\.\\w+)*', text):\n",
    "            return False\n",
    "\n",
    "        # Remove comma-separated attributes 'f6e1ef7a-107f-419e-ab7d-a51aa49c13d2.xmi.uml'\n",
    "        if re.search(r'^\\w+?(?:,\\w+?)+', text):\n",
    "            return False\n",
    "    else: \n",
    "        return False\n",
    "    \n",
    "    # All cases do not match, text may stay\n",
    "    return True\n",
    "\n",
    "data_dict = {\n",
    "    filename: {\n",
    "        metadata: list(filter(lambda x: should_be_kept(x), texts))\n",
    "        for metadata, texts in extracted_data.items()\n",
    "    }\n",
    "    for filename, extracted_data in tqdm(data_dict.items())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total amount of unique classes\n",
    "print(len(np.unique(np.array(list(map(lambda x: x.strip(), flatten([data_dict[file]['classes'] for file in data_dict.keys()])))))))\n",
    "\n",
    "# Get total amount of unique attributes\n",
    "print(len(np.unique(np.array(flatten([[str(attr).strip() for attr in values['attributes']] for values in data_dict.values() if 'attributes' in values.keys()])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove classes/attributes keys if they don't hold any values\n",
    "iteration_copy = copy.deepcopy(data_dict)\n",
    "for file in tqdm(iteration_copy.keys()):\n",
    "    for metadata in iteration_copy[file].keys():\n",
    "        if len(iteration_copy[file][metadata]) == 0:\n",
    "            del data_dict[file][metadata]\n",
    "\n",
    "# Remove files from dataset if they don't hold any classes and attributes anymore\n",
    "iteration_copy = copy.deepcopy(data_dict)\n",
    "for file in tqdm(iteration_copy.keys()):\n",
    "    if len(iteration_copy[file].keys()) == 0:\n",
    "        del data_dict[file]\n",
    "\n",
    "# Clear up memory\n",
    "del iteration_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/genmymodel_uml_extracted_metadata_cleaned1.json', 'w') as fp:\n",
    "    json.dump(data_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language detection\n",
    "\n",
    "Because the dataset contains attributes and classes in lots of languages, we want to identify all the English files that contain attributes and classes, and filter out all the rest. For this, we use FastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload data_dict from file\n",
    "with open('data/genmymodel_uml_extracted_metadata_cleaned1.json') as json_file:\n",
    "    data_dict = json.load(json_file)\n",
    "\n",
    "    # Make sure all programmic cases are turned into spaces like \"normal\" text for better language detection\n",
    "    cleaned_data = {\n",
    "        file: {\n",
    "            key: list(map(lambda x: ' '.join(list(map(lambda data_str: re.sub(r'((?<=[a-z])[A-Z]|(?<!\\A)[A-Z](?=[a-z]))', r' \\1', data_str.replace('_', ' ').strip()).lower(), x.split(' ')))), value))\n",
    "            for key, value in metadata.items()\n",
    "        } \n",
    "        for file, metadata in tqdm(data_dict.items())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_PATH = 'data/lid.176.bin'\n",
    "\n",
    "model = fasttext.load_model(PRETRAINED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate the language from the extracted classes and attributes\n",
    "def get_file_language(metadata):\n",
    "    # Combine all classes and attributes into one array\n",
    "    all_metadata = sum(metadata.values(), [])\n",
    "    \n",
    "    # Detect language for each word\n",
    "    predictions = model.predict(all_metadata)\n",
    "    \n",
    "    # Specific approach for longer texts due to issue with habit of using English in programming\n",
    "    def get_field_level_prediction(string):\n",
    "        # Split into single words to detect on word level\n",
    "        words = string.split(' ')\n",
    "        \n",
    "        # Get single-word predictions\n",
    "        string_predictions = np.array(model.predict(words))\n",
    "        \n",
    "        # Return the appropriate language\n",
    "        if len(string_predictions) == 1:\n",
    "            return string_predictions[0][0][0]\n",
    "        else:\n",
    "            # Option 1: all identical language identification\n",
    "            if len(np.unique(string_predictions[0])) == 1:\n",
    "                return string_predictions[0][0][0]\n",
    "            \n",
    "            # Option 2: combination of an English programmatic word with another language, e.g. \"hovedmenu view\"\n",
    "            elif len(string_predictions) == 2 and any('__label__en' in label for label in string_predictions):\n",
    "                return [x for x in map(lambda x: x[0], string_predictions[0]) if x != '__label__en'][0]\n",
    "            \n",
    "            # Option 3: majority vote\n",
    "            else:\n",
    "                return Counter(map(lambda x: x[0], string_predictions[0])).most_common(1)[0][0]\n",
    "        \n",
    "    # Apply to all fields, identify language for all classes and attributes\n",
    "    predictions = list(map(lambda x: get_field_level_prediction(x), all_metadata))\n",
    "\n",
    "    # Get the most common language from all attributes\n",
    "    return Counter(predictions).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_cleaned_data = {\n",
    "    key: {**value, **{'lang': get_file_language(value)}}\n",
    "    for key, value in tqdm(cleaned_data.items())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labeled_cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/genmymodel_uml_extracted_metadata_annotated.json', 'w') as fp:\n",
    "    json.dump(labeled_cleaned_data, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/genmymodel_uml_extracted_metadata_annotated.json') as json_file:\n",
    "    labeled_cleaned_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_files = {key: value for key, value in labeled_cleaned_data.items() if value['lang'] == '__label__en'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove hand-picked files\n",
    "for file in ['_0se6kFNjEeS7SK6lkmJgjw.xmi.uml', '_zeUN8FJjEeeTnI9B59buBQ.xmi.uml', '_HKUJMMGAEeSBntdMhqoN9Q.xmi.uml', '48ecca9d-91d4-44f2-a21f-b0285228d504.xmi.uml']:\n",
    "    del filtered_files[file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_files['_vZBssKMfEeScLuNN63kNaQ.xmi.uml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_transform(text):\n",
    "    # Remove HTML tags and other tags '_WZQeEMJ8EeSII650IQ0Z1w.xmi.uml'\n",
    "    text = re.sub(r'<\\w+?>', '', text)\n",
    "\n",
    "    # Remove dollar sign at the beginning '_2p9bEMasEeadwOIOqK-0Fw.xmi.uml'\n",
    "    text = re.sub(r'^\\$(?=\\w+)', '', text)\n",
    "    \n",
    "    # Remove all \"my\" things '_8y0sAIKDEeeveJPbhFhy-g.xmi.uml'\n",
    "    text = text.replace('my ', '')\n",
    "\n",
    "    # Replace all parentheses with spaces '_2A0eUK99EealN5YbbDMqoA.xmi.uml' '_UxXH4Ji_EeWP9KF1Y_wKUg.xmi.uml'\n",
    "    text = re.sub(r'\\(\\w+?\\)', '', text)\n",
    "    text = text.replace('(', ' ')\n",
    "    text = text.replace(')', ' ')\n",
    "    \n",
    "    # Remove all attached numbers '_cOog0CIgEeisAYMSV00L2Q.xmi.uml'\n",
    "    text = re.sub(r'(?<=\\w)\\d', '', text)\n",
    "\n",
    "    # Replace \"impl\" with something '19515821-de9c-4371-ab13-0c10c1f0741e.xmi.uml'\n",
    "    text = re.sub(r'\\bimpl\\b', 'implementation', text)\n",
    "\n",
    "    # Remove questions '_arOCQOkeEeiV94kHgjpOMg.xmi.uml'\n",
    "    text = re.sub(r'(?<=\\w)\\?', '', text)\n",
    "\n",
    "    # Re-combine dashes '_vZBssKMfEeScLuNN63kNaQ.xmi.uml'\n",
    "    text = re.sub(r'-\\s(?=\\w+?)', '-', text)\n",
    "\n",
    "    # Turn ref abbreviation into reference '_w-4dMCDQEeqqcaoAsxFIeg.xmi.uml'\n",
    "    text = re.sub(r'\\bref\\b', 'reference', text)\n",
    "\n",
    "    # Remove single letter with space at beginning '_zTVWYHphEeas_KSqa81bqw.xmi.uml'\n",
    "    text = re.sub(r'^\\w\\s(?=\\w+)', '', text)\n",
    "    \n",
    "    # Remove colons\n",
    "    text = text.replace(':', ' ')\n",
    "\n",
    "    # Remove duplicate spaces\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    \n",
    "    # Remove scripted pattern \" comments\";\n",
    "    text = re.sub(r'\" (.+)\";{0,1}', r'\\1', text)\n",
    "    \n",
    "    # Remove all blokhaken\n",
    "    text = re.sub(r'\\[.*\\]', '', text)\n",
    "    \n",
    "    # Remove dash to start\n",
    "    text = re.sub(r'^-', '', text)\n",
    "    \n",
    "    # Remove plus to start\n",
    "    text = re.sub(r'^\\+', '', text)\n",
    "    \n",
    "    # Replace # with number when at end\n",
    "    text = re.sub(r' ?#$', ' number', text)\n",
    "    \n",
    "    # Replace # with number at start\n",
    "    text = re.sub(r'^#', 'number ', text)\n",
    "    \n",
    "    # Replace all dashes with spaces\n",
    "    text = text.replace('-', ' ')\n",
    "    \n",
    "    # Remove * + \n",
    "    text = re.sub('\\*$', '', text)\n",
    "    text = re.sub('[\\?]', '', text)\n",
    "    \n",
    "    # Remove tags\n",
    "    text = re.sub(r'.+?< ([\\w\\s]+)>', r'\\1', text)\n",
    "    text = re.sub(r'^<>', '', text)\n",
    "    text = re.sub(r'<$', '', text)\n",
    "    \n",
    "    # Change ampersand to \"and\"\n",
    "    text = text.replace(' & ', ' and ')\n",
    "    \n",
    "    # Replace backslash in front\n",
    "    text = re.sub(r'^\\\\ ', '', text)\n",
    "    \n",
    "    # Remove duplicate spaces\n",
    "    text = text.replace('  ', ' ')\n",
    "    \n",
    "    # Trim output\n",
    "    return text.strip()\n",
    "\n",
    "text_transform('abstract resource item< style sheet item, style sheet params,url>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_files = {\n",
    "    filename: {\n",
    "        metadata: list(map(lambda x: text_transform(x), texts))\n",
    "        for metadata, texts in extracted_data.items()\n",
    "        if metadata != 'lang'\n",
    "    }\n",
    "    for filename, extracted_data in tqdm(filtered_files.items())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latin_letters= {}\n",
    "\n",
    "def is_latin(uchr):\n",
    "    try: return latin_letters[uchr]\n",
    "    except KeyError:\n",
    "         return latin_letters.setdefault(uchr, 'LATIN' in ud.name(uchr))\n",
    "\n",
    "def only_roman_chars(unistr):\n",
    "    return all(is_latin(uchr)\n",
    "           for uchr in unistr\n",
    "           if uchr.isalpha())\n",
    "\n",
    "def not_three_consecutive_chars(unistr):\n",
    "    start = unistr[0]\n",
    "    \n",
    "    for char in unistr[1:]:\n",
    "        if char == start[0]:\n",
    "            start = start + char\n",
    "            \n",
    "            if len(start) > 2:\n",
    "                return False\n",
    "        else:\n",
    "            start = char\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create non-changing copy for iteration through the files\n",
    "iteration_copy = copy.deepcopy(filtered_files)\n",
    "\n",
    "for file in iteration_copy.keys():\n",
    "    for metadata in iteration_copy[file].keys():\n",
    "        # Remove all empty strings and non-alphanumerical entries\n",
    "        new_metadata = list(filter(lambda x: x != '' and len(x) > 1 and x.replace(' ', '').replace(\"'\", '').isalnum() and only_roman_chars(x) and any(c.isalpha() for c in x) and len(set(filter(str.isalpha, x))) != 1 and not re.match(r'(?:aa)|(?:uu)|(?:yy)|(?:ii)|(?:jj)', x) and not_three_consecutive_chars(x) and not '0f' in x and model.predict([x])[0][0][0] == '__label__en', filtered_files[file][metadata]))\n",
    "        \n",
    "        # Either remove the now-empty metadata or change it in the file\n",
    "        if len(new_metadata) > 0:\n",
    "            filtered_files[file][metadata] = new_metadata\n",
    "        else:\n",
    "            del filtered_files[file][metadata]\n",
    "    \n",
    "    # Remove file if it doesn't contain metadata anymore after filtering\n",
    "    if len(filtered_files[file].keys()) == 0:\n",
    "        del filtered_files[file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/genmymodel_uml_extracted_metadata_final.json', 'w') as fp:\n",
    "    json.dump(filtered_files, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
