{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/martijnschouten/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/martijnschouten/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics as crf_metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "import gensim\n",
    "import json \n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-crfsuite in /opt/anaconda3/lib/python3.8/site-packages (0.3.6)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from sklearn-crfsuite) (1.15.0)\n",
      "Requirement already satisfied: tabulate in /opt/anaconda3/lib/python3.8/site-packages (from sklearn-crfsuite) (0.8.9)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /opt/anaconda3/lib/python3.8/site-packages (from sklearn-crfsuite) (0.9.7)\n",
      "Requirement already satisfied: tqdm>=2.0 in /opt/anaconda3/lib/python3.8/site-packages (from sklearn-crfsuite) (4.62.3)\n",
      "Requirement already satisfied: scikit-learn<0.24 in /opt/anaconda3/lib/python3.8/site-packages (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn<0.24) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn<0.24) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn<0.24) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn<0.24) (2.1.0)\n",
      "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.8/site-packages (4.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-crfsuite -U\n",
    "!pip install -U 'scikit-learn<0.24'\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train-full.tsv', sep='\\t')\n",
    "validation_df = pd.read_csv('../data/validation-full.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['doc-sent'] = [str(row.document_ID) + '-' + str(row.sentence_ID) for index, row in train_df.iterrows()]\n",
    "validation_df['doc-sent'] = [str(row.document_ID) + '-' + str(row.sentence_ID) for index, row in validation_df.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new columns\n",
    "train_df['total_occurences'] = 0\n",
    "train_df['class_occurences'] = 0\n",
    "train_df['attribute_occurences'] = 0\n",
    "validation_df['total_occurences'] = 0\n",
    "validation_df['class_occurences'] = 0\n",
    "validation_df['attribute_occurences'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/genmymodel/genmymodel_uml_extracted_metadata_final.json') as json_file:\n",
    "    gmm_data = json.load(json_file)\n",
    "\n",
    "# Store all classes and attributes independent of eachother\n",
    "all_classes = []\n",
    "all_attrs = []\n",
    "\n",
    "# Loop over all metadata and append to proper list\n",
    "for file, metadata in gmm_data.items():\n",
    "    if 'classes' in metadata.keys():\n",
    "        all_classes.append(metadata['classes'])\n",
    "\n",
    "    if 'attributes' in metadata.keys():\n",
    "        all_attrs.append(metadata['attributes'])\n",
    "\n",
    "flatten = lambda t: [item for sublist in t for item in sublist]\n",
    "\n",
    "all_classes = flatten(all_classes)\n",
    "all_attrs = flatten(all_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccef101f072484f891b869b5d4f640e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noungroup = []\n",
    "noungroup_indices = []\n",
    "\n",
    "for index, row in tqdm(train_df.iterrows()):\n",
    "    if isinstance(row['fine_POS_tag'], str) and row['fine_POS_tag'][:2] == 'NN':\n",
    "        noungroup.append(row['word'])\n",
    "        noungroup_docsents.append(index)\n",
    "    else:\n",
    "        if len(noungroup) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            full_ng = ' '.join(noungroup).lower()\n",
    "            attr_no = all_attrs.count(full_ng)\n",
    "            class_no = all_classes.count(full_ng)\n",
    "            \n",
    "            for noun_index in noungroup_docsents:\n",
    "                train_df.loc[noun_index, ['class_occurences', 'attribute_occurences', 'total_occurences']] = [class_no, attr_no, attr_no + class_no]\n",
    "                \n",
    "            noungroup = []\n",
    "            noungroup_docsents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d65a138e9e4686bf4fcaad8ac192ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noungroup = []\n",
    "noungroup_indices = []\n",
    "\n",
    "for index, row in tqdm(validation_df.iterrows()):\n",
    "    if isinstance(row['fine_POS_tag'], str) and row['fine_POS_tag'][:2] == 'NN':\n",
    "        noungroup.append(row['word'])\n",
    "        noungroup_indices.append(index)\n",
    "    else:\n",
    "        if len(noungroup) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            full_ng = ' '.join(noungroup).lower()\n",
    "            attr_no = all_attrs.count(full_ng)\n",
    "            class_no = all_classes.count(full_ng)\n",
    "            \n",
    "            for noun_index in noungroup_indices:\n",
    "                validation_df.loc[noun_index, ['class_occurences', 'attribute_occurences', 'total_occurences']] = [class_no, attr_no, attr_no + class_no]\n",
    "                \n",
    "            noungroup = []\n",
    "            noungroup_indices = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare IOB format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['doc-sent', 'word', 'lemma', 'POS_tag', 'fine_POS_tag', 'dependency_relation', 'event', 'supersense_category', 'entity', 'entity_type', 'entity_category', 'total_occurences', 'class_occurences', 'attribute_occurences', 'IOB_tag']\n",
    "train_df = train_df[columns]\n",
    "validation_df = validation_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s: list(map(lambda w: tuple(w), s.loc[:, s.columns != 'doc-sent'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grouped_df = train_df.groupby('doc-sent').apply(agg_func)\n",
    "validation_grouped_df = validation_df.groupby('doc-sent').apply(agg_func)\n",
    "\n",
    "train_sentences = [s for s in train_grouped_df]\n",
    "validation_sentences = [s for s in validation_grouped_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc-sent\n",
       "0-0      [(This, this, PRON, DT, nsubj, O, nan, nan, na...\n",
       "0-1      [(The, the, DET, DT, det, O, nan, nan, nan, na...\n",
       "0-10     [(Section, section, NOUN, NN, nsubj, O, noun.c...\n",
       "0-100    [(The, the, DET, DT, det, O, nan, nan, nan, na...\n",
       "0-101    [(Metadata, Metadata, PROPN, NNP, nmod, O, nou...\n",
       "                               ...                        \n",
       "9-95     [(The, the, DET, DT, det, O, nan, nan, nan, na...\n",
       "9-96     [(The, the, DET, DT, det, O, nan, nan, nan, na...\n",
       "9-97     [(The, the, DET, DT, det, O, nan, nan, nan, na...\n",
       "9-98     [(The, the, DET, DT, det, O, nan, nan, nan, na...\n",
       "9-99     [(The, the, DET, DT, det, O, nan, nan, nan, na...\n",
       "Length: 2639, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-89-91becf894d8f>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.dropna(subset=['doc-sent'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_df.dropna(subset=['doc-sent'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastText model for embedding generation\n",
    "vocab = train_df['word'].values.tolist() + validation_df['word'].values.tolist()\n",
    "model = gensim.models.FastText(vocab, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('fasttext-model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i, embedding, ratio):\n",
    "    word = sent[i][1]\n",
    "    postag = sent[i][3]\n",
    "    fine_postag = sent[i][4]\n",
    "    \n",
    "    features = {\n",
    "        label: data\n",
    "        for label, data in zip(columns[1:-1], sent[i][:-1])\n",
    "    }\n",
    "    \n",
    "    features.update({\n",
    "        'word.lower()': word.lower(),\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'postag[:2]': postag[:2],\n",
    "        'postag[:2]': postag[:2],\n",
    "        'finepostag[:2]': fine_postag[:2],\n",
    "        'finepostag[:2]': fine_postag[:2],\n",
    "    })\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][1]\n",
    "        postag1 = sent[i-1][3]\n",
    "        finepostag1 = sent[i-1][4]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "            '-1:finepostag': finepostag1,\n",
    "            '-1:finepostag[:2]': finepostag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][1]\n",
    "        postag1 = sent[i+1][3]\n",
    "        finepostag1 = sent[i-1][4]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "            '+1:finepostag': finepostag1,\n",
    "            '+1:finepostag[:2]': finepostag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "    \n",
    "    if not ratio:\n",
    "        for ratio_feature in ['total_occurences', 'class_occurences', 'attribute_occurences']:\n",
    "            del features[ratio_feature]\n",
    "        \n",
    "    if embedding:\n",
    "        word_embedding = model.wv.get_vector(word)\n",
    "        \n",
    "        features.update({\n",
    "            f'emb_pos_{i}': word_embedding[i]\n",
    "            for i in range(len(word_embedding))\n",
    "        })\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent, embedding = False, ratio = False):\n",
    "    return [word2features(sent, i, embedding, ratio) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return list(map(lambda s: s[-1], sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'The',\n",
       "  'lemma': 'the',\n",
       "  'POS_tag': 'DET',\n",
       "  'fine_POS_tag': 'DT',\n",
       "  'dependency_relation': 'det',\n",
       "  'event': 'O',\n",
       "  'supersense_category': nan,\n",
       "  'entity': 1.0,\n",
       "  'entity_type': 'NOM',\n",
       "  'entity_category': 'FAC',\n",
       "  'word.lower()': 'the',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'word[-3:]': 'the',\n",
       "  'word[-2:]': 'he',\n",
       "  'postag[:2]': 'DT',\n",
       "  'finepostag[:2]': 'de',\n",
       "  'BOS': True,\n",
       "  '+1:word.lower()': 'clinic',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NN',\n",
       "  '+1:postag[:2]': 'NN',\n",
       "  '+1:finepostag': 'conj',\n",
       "  '+1:finepostag[:2]': 'co'},\n",
       " {'word': 'clinic',\n",
       "  'lemma': 'clinic',\n",
       "  'POS_tag': 'NOUN',\n",
       "  'fine_POS_tag': 'NN',\n",
       "  'dependency_relation': 'nsubj',\n",
       "  'event': 'O',\n",
       "  'supersense_category': 'noun.group',\n",
       "  'entity': 1.0,\n",
       "  'entity_type': 'NOM',\n",
       "  'entity_category': 'FAC',\n",
       "  'word.lower()': 'clinic',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'word[-3:]': 'nic',\n",
       "  'word[-2:]': 'ic',\n",
       "  'postag[:2]': 'NN',\n",
       "  'finepostag[:2]': 'ns',\n",
       "  '-1:word.lower()': 'the',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'DT',\n",
       "  '-1:postag[:2]': 'DT',\n",
       "  '-1:finepostag': 'det',\n",
       "  '-1:finepostag[:2]': 'de',\n",
       "  '+1:word.lower()': 'basically',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'RB',\n",
       "  '+1:postag[:2]': 'RB',\n",
       "  '+1:finepostag': 'det',\n",
       "  '+1:finepostag[:2]': 'de'},\n",
       " {'word': 'basically',\n",
       "  'lemma': 'basically',\n",
       "  'POS_tag': 'ADV',\n",
       "  'fine_POS_tag': 'RB',\n",
       "  'dependency_relation': 'advmod',\n",
       "  'event': 'O',\n",
       "  'supersense_category': nan,\n",
       "  'entity': nan,\n",
       "  'entity_type': nan,\n",
       "  'entity_category': nan,\n",
       "  'word.lower()': 'basically',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'word[-3:]': 'lly',\n",
       "  'word[-2:]': 'ly',\n",
       "  'postag[:2]': 'RB',\n",
       "  'finepostag[:2]': 'ad',\n",
       "  '-1:word.lower()': 'clinic',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NN',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '-1:finepostag': 'nsubj',\n",
       "  '-1:finepostag[:2]': 'ns',\n",
       "  '+1:word.lower()': 'schedule',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'VBZ',\n",
       "  '+1:postag[:2]': 'VB',\n",
       "  '+1:finepostag': 'nsubj',\n",
       "  '+1:finepostag[:2]': 'ns'},\n",
       " {'word': 'schedules',\n",
       "  'lemma': 'schedule',\n",
       "  'POS_tag': 'VERB',\n",
       "  'fine_POS_tag': 'VBZ',\n",
       "  'dependency_relation': 'ROOT',\n",
       "  'event': 'O',\n",
       "  'supersense_category': 'verb.cognition',\n",
       "  'entity': nan,\n",
       "  'entity_type': nan,\n",
       "  'entity_category': nan,\n",
       "  'word.lower()': 'schedule',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'word[-3:]': 'ule',\n",
       "  'word[-2:]': 'le',\n",
       "  'postag[:2]': 'VB',\n",
       "  'finepostag[:2]': 'RO',\n",
       "  '-1:word.lower()': 'basically',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'RB',\n",
       "  '-1:postag[:2]': 'RB',\n",
       "  '-1:finepostag': 'advmod',\n",
       "  '-1:finepostag[:2]': 'ad',\n",
       "  '+1:word.lower()': 'patient',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NNS',\n",
       "  '+1:postag[:2]': 'NN',\n",
       "  '+1:finepostag': 'advmod',\n",
       "  '+1:finepostag[:2]': 'ad'},\n",
       " {'word': 'patients',\n",
       "  'lemma': 'patient',\n",
       "  'POS_tag': 'NOUN',\n",
       "  'fine_POS_tag': 'NNS',\n",
       "  'dependency_relation': 'dobj',\n",
       "  'event': 'O',\n",
       "  'supersense_category': 'noun.person',\n",
       "  'entity': 2.0,\n",
       "  'entity_type': 'NOM',\n",
       "  'entity_category': 'PER',\n",
       "  'word.lower()': 'patient',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'word[-3:]': 'ent',\n",
       "  'word[-2:]': 'nt',\n",
       "  'postag[:2]': 'NN',\n",
       "  'finepostag[:2]': 'do',\n",
       "  '-1:word.lower()': 'schedule',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'VBZ',\n",
       "  '-1:postag[:2]': 'VB',\n",
       "  '-1:finepostag': 'ROOT',\n",
       "  '-1:finepostag[:2]': 'RO',\n",
       "  '+1:word.lower()': ',',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': ',',\n",
       "  '+1:postag[:2]': ',',\n",
       "  '+1:finepostag': 'ROOT',\n",
       "  '+1:finepostag[:2]': 'RO'},\n",
       " {'word': ',',\n",
       "  'lemma': ',',\n",
       "  'POS_tag': 'PUNCT',\n",
       "  'fine_POS_tag': ',',\n",
       "  'dependency_relation': 'punct',\n",
       "  'event': 'O',\n",
       "  'supersense_category': nan,\n",
       "  'entity': nan,\n",
       "  'entity_type': nan,\n",
       "  'entity_category': nan,\n",
       "  'word.lower()': ',',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'word[-3:]': ',',\n",
       "  'word[-2:]': ',',\n",
       "  'postag[:2]': ',',\n",
       "  'finepostag[:2]': 'pu',\n",
       "  '-1:word.lower()': 'patient',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NNS',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '-1:finepostag': 'dobj',\n",
       "  '-1:finepostag[:2]': 'do',\n",
       "  '+1:word.lower()': 'provide',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'VBZ',\n",
       "  '+1:postag[:2]': 'VB',\n",
       "  '+1:finepostag': 'dobj',\n",
       "  '+1:finepostag[:2]': 'do'},\n",
       " {'word': 'provides',\n",
       "  'lemma': 'provide',\n",
       "  'POS_tag': 'VERB',\n",
       "  'fine_POS_tag': 'VBZ',\n",
       "  'dependency_relation': 'conj',\n",
       "  'event': 'O',\n",
       "  'supersense_category': 'verb.possession',\n",
       "  'entity': nan,\n",
       "  'entity_type': nan,\n",
       "  'entity_category': nan,\n",
       "  'word.lower()': 'provide',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'word[-3:]': 'ide',\n",
       "  'word[-2:]': 'de',\n",
       "  'postag[:2]': 'VB',\n",
       "  'finepostag[:2]': 'co',\n",
       "  '-1:word.lower()': ',',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': ',',\n",
       "  '-1:postag[:2]': ',',\n",
       "  '-1:finepostag': 'punct',\n",
       "  '-1:finepostag[:2]': 'pu',\n",
       "  'EOS': True}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(validation_sentences[0][:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-23d048e067d6>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train = np.array([sent2features(s) for s in train_sentences])\n",
      "<ipython-input-12-23d048e067d6>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test = np.array([sent2features(s) for s in validation_sentences])\n",
      "<ipython-input-12-23d048e067d6>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_train = np.array([sent2labels(s) for s in train_sentences])\n",
      "<ipython-input-12-23d048e067d6>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_test = np.array([sent2labels(s) for s in validation_sentences])\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([sent2features(s) for s in train_sentences])\n",
    "X_test = np.array([sent2features(s) for s in validation_sentences])\n",
    "y_train = np.array([sent2labels(s) for s in train_sentences])\n",
    "y_test = np.array([sent2labels(s) for s in validation_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(train_df['IOB_tag'].unique())\n",
    "labels.remove('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=CRF(algorithm='lbfgs',\n",
       "                                 all_possible_transitions=True,\n",
       "                                 keep_tempfiles=None, max_iterations=100),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7faecb1cd880>,\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7faecb1cdc40>},\n",
       "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=['B-class', 'I-class', 'B-attr', 'I-attr']),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(crf_metrics.flat_f1_score, average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-class', 'I-class', 'B-attr', 'I-attr']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-class      0.628     0.274     0.382       215\n",
      "     I-class      0.591     0.153     0.243        85\n",
      "      B-attr      0.677     0.300     0.416       140\n",
      "      I-attr      0.730     0.338     0.462       136\n",
      "\n",
      "   micro avg      0.664     0.278     0.392       576\n",
      "   macro avg      0.657     0.266     0.376       576\n",
      "weighted avg      0.659     0.278     0.389       576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass labels=['B-class', 'I-class', 'B-attr', 'I-attr'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "print(crf_metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['The', 'O'],\n",
       "  ['clinic', 'B-class'],\n",
       "  ['basically', 'O'],\n",
       "  ['schedules', 'O'],\n",
       "  ['patients', 'B-class'],\n",
       "  [',', 'O'],\n",
       "  ['provides', 'O'],\n",
       "  ['services', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['them', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['bills', 'O'],\n",
       "  ['them', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['those', 'O'],\n",
       "  ['services', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['New', 'O'],\n",
       "  ['patients', 'B-class'],\n",
       "  ['fill', 'O'],\n",
       "  ['out', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['form', 'O'],\n",
       "  ['listing', 'O'],\n",
       "  ['their', 'O'],\n",
       "  ['name', 'B-attr'],\n",
       "  [',', 'O'],\n",
       "  ['address', 'B-attr'],\n",
       "  [',', 'O'],\n",
       "  ['telephone', 'B-attr'],\n",
       "  ['numbers', 'I-attr'],\n",
       "  [',', 'O'],\n",
       "  ['allergies', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['state', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['mind', 'O'],\n",
       "  ['prior', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['scheduling', 'O'],\n",
       "  ['their', 'O'],\n",
       "  ['first', 'O'],\n",
       "  ['appointment', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Billing', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['always', 'O'],\n",
       "  ['done', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['month', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['bills', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['always', 'O'],\n",
       "  ['sent', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['mail', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['patients', 'B-class'],\n",
       "  [\"'\", 'O'],\n",
       "  ['contact', 'B-attr'],\n",
       "  ['addresses', 'I-attr'],\n",
       "  ['.', 'O']],\n",
       " [['Checks', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['received', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['mail', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['HMO', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['funded', 'O'],\n",
       "  ['patients', 'B-class'],\n",
       "  ['are', 'O'],\n",
       "  ['asked', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['make', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['copayment', 'B-class'],\n",
       "  ['at', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['time', 'O'],\n",
       "  ['that', 'O'],\n",
       "  ['they', 'O'],\n",
       "  ['leave', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['office', 'B-class'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['patient', 'B-class'],\n",
       "  ['also', 'O'],\n",
       "  ['generates', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['reimbursement', 'O'],\n",
       "  ['request', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['insurance', 'O'],\n",
       "  ['company', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Insurance', 'O'],\n",
       "  ['companies', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['HMOs', 'O'],\n",
       "  ['send', 'O'],\n",
       "  ['their', 'O'],\n",
       "  ['checks', 'B-class'],\n",
       "  ['by', 'O'],\n",
       "  ['mail', 'O'],\n",
       "  ['three', 'O'],\n",
       "  ['months', 'O'],\n",
       "  ['after', 'O'],\n",
       "  ['receiving', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['reimbursement', 'O'],\n",
       "  ['request', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['The', 'O'],\n",
       "  ['clinic', 'B-class'],\n",
       "  ['maintains', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['supplies', 'B-class'],\n",
       "  ['inventory', 'I-class'],\n",
       "  ['file', 'I-class'],\n",
       "  ['that', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['worker', 'O'],\n",
       "  ['fills', 'O'],\n",
       "  ['out', 'O'],\n",
       "  ['once', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['week', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['physically', 'O'],\n",
       "  ['inspecting', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['three', 'O'],\n",
       "  ['procedures', 'O'],\n",
       "  ['rooms', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Supplies', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['tools', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['stored', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['standard', 'O'],\n",
       "  ['layout', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['room', 'B-class'],\n",
       "  ['.', 'O']],\n",
       " [['Existing', 'O'],\n",
       "  ['patients', 'B-class'],\n",
       "  ['are', 'O'],\n",
       "  ['normally', 'O'],\n",
       "  ['scheduled', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['their', 'O'],\n",
       "  ['next', 'O'],\n",
       "  ['appointment', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['they', 'O'],\n",
       "  ['depart', 'O'],\n",
       "  ['from', 'O'],\n",
       "  ['their', 'O'],\n",
       "  ['current', 'O'],\n",
       "  ['appointment', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['When', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['office', 'B-class'],\n",
       "  ['staff', 'I-class'],\n",
       "  ['forget', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['do', 'O'],\n",
       "  ['this', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['desk', 'O'],\n",
       "  ['worker', 'O'],\n",
       "  ['has', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['call', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['patient', 'B-class'],\n",
       "  ['to', 'O'],\n",
       "  ['set', 'O'],\n",
       "  ['up', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['date', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Schedules', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['entered', 'O'],\n",
       "  ['into', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['central', 'O'],\n",
       "  ['appointment', 'O'],\n",
       "  ['book', 'O'],\n",
       "  [';', 'O'],\n",
       "  ['patient', 'B-class'],\n",
       "  ['records', 'I-class'],\n",
       "  ['(', 'O'],\n",
       "  ['including', 'O'],\n",
       "  ['contact', 'B-attr'],\n",
       "  ['information', 'I-attr'],\n",
       "  [')', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['kept', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['paper', 'O'],\n",
       "  ['files', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Appointments', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['one', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['three', 'O'],\n",
       "  ['procedures', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['dental', 'O'],\n",
       "  ['hygiene', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['cavities', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['fillings', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['oral', 'O'],\n",
       "  ['surgery', 'O'],\n",
       "  ['(', 'O'],\n",
       "  ['including', 'O'],\n",
       "  ['root', 'O'],\n",
       "  ['canals', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['tooth', 'O'],\n",
       "  ['extractions', 'O'],\n",
       "  [')', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['For', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['procedure', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['patient', 'B-class'],\n",
       "  ['needs', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['prepared', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['supplies', 'O'],\n",
       "  ['need', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['collected', 'O'],\n",
       "  ['(', 'O'],\n",
       "  ['e.g.', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['probes', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['drill', 'O'],\n",
       "  ['bits', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['cements', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['resins', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['etc', 'O'],\n",
       "  ['.', 'O'],\n",
       "  [')', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['For', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['hygienist', 'O'],\n",
       "  [\"'s\", 'O'],\n",
       "  ['appointment', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['preparation', 'O'],\n",
       "  ['could', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['simple', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['seating', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['patient', 'B-class'],\n",
       "  ['in', 'O'],\n",
       "  ['dental', 'O'],\n",
       "  ['chair', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['putting', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['bib', 'O'],\n",
       "  ['around', 'O'],\n",
       "  ['his', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['her', 'O'],\n",
       "  ['neck', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['For', 'O'],\n",
       "  ['oral', 'O'],\n",
       "  ['surgery', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['anesthesia', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['various', 'O'],\n",
       "  ['strengths', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['normally', 'O'],\n",
       "  ['administered', 'O'],\n",
       "  ['prior', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['operation', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Only', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['oral', 'O'],\n",
       "  ['surgery', 'O'],\n",
       "  ['procedures', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['it', 'O'],\n",
       "  ['necessary', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['ask', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['patient', 'B-class'],\n",
       "  ['to', 'O'],\n",
       "  ['wait', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['up', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['twenty', 'O'],\n",
       "  ['minutes', 'O'],\n",
       "  ['before', 'O'],\n",
       "  ['performing', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['post', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['operative', 'O'],\n",
       "  ['check', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Geological', 'O'],\n",
       "  ['samples', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['retrieved', 'O'],\n",
       "  ['from', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['field', 'B-class'],\n",
       "  ['and', 'O'],\n",
       "  ['then', 'O'],\n",
       "  ['processed', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['laboratory', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['determine', 'O'],\n",
       "  ['various', 'O'],\n",
       "  ['properties', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['including', 'O'],\n",
       "  ['chemistry', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['mineralogy', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['age', 'B-attr'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['petrophysical', 'B-attr'],\n",
       "  ['properties', 'I-attr'],\n",
       "  ['like', 'O'],\n",
       "  ['density', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['porosity', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['permeability', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Samples', 'O'],\n",
       "  ['obtained', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['part', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['economic', 'O'],\n",
       "  ['activities', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['such', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['mineral', 'O'],\n",
       "  ['exploration', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['usually', 'O'],\n",
       "  ['processed', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['commercial', 'O'],\n",
       "  ['assay', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['chemistry', 'O'],\n",
       "  ['labs', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['These', 'O'],\n",
       "  ['samples', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['sometimes', 'O'],\n",
       "  ['sub', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['divided', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['distributed', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['multiple', 'O'],\n",
       "  ['research', 'O'],\n",
       "  ['teams', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['labs', 'B-class'],\n",
       "  ['for', 'O'],\n",
       "  ['different', 'O'],\n",
       "  ['specialized', 'O'],\n",
       "  ['observations', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['lab', 'B-class'],\n",
       "  ['will', 'O'],\n",
       "  ['run', 'O'],\n",
       "  ['its', 'O'],\n",
       "  ['own', 'O'],\n",
       "  ['LIMS', 'O'],\n",
       "  ['system', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['which', 'O'],\n",
       "  ['will', 'O'],\n",
       "  ['usually', 'O'],\n",
       "  ['assign', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['local', 'B-attr'],\n",
       "  ['identifier', 'I-attr'],\n",
       "  ['for', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['sample', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['When', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['results', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['these', 'O'],\n",
       "  ['observations', 'B-class'],\n",
       "  ['are', 'O'],\n",
       "  ['reported', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['it', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['necessary', 'O'],\n",
       "  ['that', 'O'],\n",
       "  ['observations', 'B-class'],\n",
       "  ['from', 'O'],\n",
       "  ['different', 'O'],\n",
       "  ['labs', 'B-class'],\n",
       "  ['can', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['correlated', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['other', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['so', 'O'],\n",
       "  ['that', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['complete', 'O'],\n",
       "  ['picture', 'O'],\n",
       "  ['around', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['sample', 'O'],\n",
       "  ['can', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['assembled', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['These', 'O'],\n",
       "  ['stories', 'O'],\n",
       "  ['focus', 'O'],\n",
       "  ['on', 'O'],\n",
       "  ['sensing', 'O'],\n",
       "  ['applications', 'O'],\n",
       "  ['involving', 'O'],\n",
       "  ['ex', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['situ', 'O'],\n",
       "  ['sampling', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['where', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['location', 'B-class'],\n",
       "  ['is', 'O'],\n",
       "  ['visited', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['specimen', 'O'],\n",
       "  ['obtained', 'O'],\n",
       "  ['using', 'O'],\n",
       "  ['some', 'O'],\n",
       "  ['sampling', 'O'],\n",
       "  ['process', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['then', 'O'],\n",
       "  ['transported', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['one', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['more', 'O'],\n",
       "  ['laboratories', 'O'],\n",
       "  ['where', 'O'],\n",
       "  ['it', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['processed', 'O'],\n",
       "  ['into', 'O'],\n",
       "  ['one', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['more', 'O'],\n",
       "  ['sub', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['samples', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['various', 'O'],\n",
       "  ['observations', 'B-class'],\n",
       "  ['made', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Sample', 'O'],\n",
       "  ['identity', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['usually', 'O'],\n",
       "  ['key', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['relationships', 'B-class'],\n",
       "  ['between', 'O'],\n",
       "  ['samples', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['between', 'O'],\n",
       "  ['samples', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['other', 'O'],\n",
       "  ['artifacts', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['sampling', 'O'],\n",
       "  ['process', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['also', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['other', 'O'],\n",
       "  ['geographic', 'O'],\n",
       "  ['features', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['locations', 'B-class'],\n",
       "  ['.', 'O']],\n",
       " [['The', 'O'],\n",
       "  ['sampling', 'O'],\n",
       "  ['time', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['analysis', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['reporting', 'O'],\n",
       "  ['time', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['all', 'O'],\n",
       "  ['different', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Similar', 'O'],\n",
       "  ['process', 'O'],\n",
       "  ['apply', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['botanical', 'O'],\n",
       "  ['sampling', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['environmental', 'O'],\n",
       "  ['sampling', 'O'],\n",
       "  ['(', 'O'],\n",
       "  ['water', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['air', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['dust', 'O'],\n",
       "  [')', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['For', 'O'],\n",
       "  ['QA', 'O'],\n",
       "  ['/', 'O'],\n",
       "  ['QC', 'O'],\n",
       "  ['purposes', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['batch', 'B-class'],\n",
       "  ['of', 'O'],\n",
       "  ['samples', 'O'],\n",
       "  ['will', 'O'],\n",
       "  ['have', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['number', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['control', 'O'],\n",
       "  ['samples', 'O'],\n",
       "  ['inserted', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['which', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['concentration', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['particular', 'O'],\n",
       "  ['chemical', 'O'],\n",
       "  ['species', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['already', 'O'],\n",
       "  ['known', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['For', 'O'],\n",
       "  ['confidentiality', 'O'],\n",
       "  ['reasons', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['location', 'B-attr'],\n",
       "  ['information', 'I-attr'],\n",
       "  ['associated', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['sample', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['not', 'O'],\n",
       "  ['provided', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['lab', 'B-class'],\n",
       "  [',', 'O'],\n",
       "  ['but', 'O'],\n",
       "  ['must', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['re', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['attached', 'O'],\n",
       "  ['during', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['interpretation', 'O'],\n",
       "  ['phase', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['During', 'O'],\n",
       "  ['processing', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['many', 'O'],\n",
       "  ['derived', 'O'],\n",
       "  ['samples', 'O'],\n",
       "  ['will', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['generated', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['various', 'O'],\n",
       "  ['physical', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['chemical', 'O'],\n",
       "  ['procedures', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['In', 'O'],\n",
       "  ['some', 'O'],\n",
       "  ['cases', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['derived', 'O'],\n",
       "  ['samples', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['strict', 'O'],\n",
       "  ['sub', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['samples', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['whose', 'O'],\n",
       "  ['intensive', 'O'],\n",
       "  ['properties', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['intended', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['same', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['parent', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['In', 'O'],\n",
       "  ['other', 'O'],\n",
       "  ['cases', 'B-class'],\n",
       "  [',', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['split', 'O'],\n",
       "  ['is', 'O'],\n",
       "  [\"'\", 'O'],\n",
       "  ['biased', 'O'],\n",
       "  [\"'\", 'O'],\n",
       "  [',', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['derived', 'O'],\n",
       "  ['sample', 'O'],\n",
       "  ['intended', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['select', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['specific', 'O'],\n",
       "  ['sub', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['sample', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['defined', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['particular', 'O'],\n",
       "  ['particle', 'O'],\n",
       "  ['size', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['density', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['magnetic', 'B-attr'],\n",
       "  ['properties', 'I-attr'],\n",
       "  [',', 'O'],\n",
       "  ['etc', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['The', 'O'],\n",
       "  ['link', 'O'],\n",
       "  ['from', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['derived', 'O'],\n",
       "  ['sample', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['parent', 'O'],\n",
       "  ['sample', 'O'],\n",
       "  ['must', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['preserved', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['link', 'O'],\n",
       "  ['from', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['parent', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['location', 'B-attr'],\n",
       "  ['from', 'O'],\n",
       "  ['which', 'O'],\n",
       "  ['it', 'O'],\n",
       "  ['was', 'O'],\n",
       "  ['obtained', 'O'],\n",
       "  ['also', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['In', 'O'],\n",
       "  ['some', 'O'],\n",
       "  ['cases', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['location', 'B-class'],\n",
       "  ['is', 'O'],\n",
       "  ['associated', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['another', 'O'],\n",
       "  ['sampling', 'O'],\n",
       "  ['artifact', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['such', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['drill', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['hole', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['traverse', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['cruise', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['latter', 'O'],\n",
       "  ['carrying', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['detailed', 'O'],\n",
       "  ['location', 'B-attr'],\n",
       "  ['information', 'I-attr'],\n",
       "  ['.', 'O']],\n",
       " [['In', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['research', 'O'],\n",
       "  ['context', 'O'],\n",
       "  ['some', 'O'],\n",
       "  ['samples', 'O'],\n",
       "  ['have', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['particularly', 'O'],\n",
       "  ['high', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['value', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['having', 'O'],\n",
       "  ['been', 'O'],\n",
       "  ['obtained', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['expensive', 'O'],\n",
       "  ['process', 'O'],\n",
       "  ['(', 'O'],\n",
       "  ['involving', 'O'],\n",
       "  ['drilling', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['ships', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['spacecraft', 'O'],\n",
       "  [')', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['from', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['location', 'B-class'],\n",
       "  ['that', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['hard', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['visit', 'O'],\n",
       "  ['(', 'O'],\n",
       "  ['remote', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['offshore', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['space', 'O'],\n",
       "  [')', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Analyst', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['Do', 'O'],\n",
       "  ['you', 'O'],\n",
       "  ['run', 'O'],\n",
       "  ['into', 'O'],\n",
       "  ['any', 'O'],\n",
       "  ['challenges', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['international', 'B-attr'],\n",
       "  ['addresses', 'I-attr'],\n",
       "  [',', 'O'],\n",
       "  ['given', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['wide', 'O'],\n",
       "  ['variation', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['address', 'O'],\n",
       "  ['formats', 'O'],\n",
       "  ['?', 'O']],\n",
       " [['AP', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['Actually', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['that', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['constant', 'O'],\n",
       "  ['source', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['confusion', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['pain', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['What', 'O'],\n",
       "  ['information', 'O'],\n",
       "  ['do', 'O'],\n",
       "  ['you', 'O'],\n",
       "  ['initially', 'O'],\n",
       "  ['record', 'O'],\n",
       "  ['about', 'O'],\n",
       "  ['that', 'O'],\n",
       "  ['person', 'O'],\n",
       "  ['?', 'O']],\n",
       " [['AP', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['Remember', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['it', 'O'],\n",
       "  ['’s', 'O'],\n",
       "  ['not', 'O'],\n",
       "  ['always', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['individual', 'O'],\n",
       "  [';', 'O'],\n",
       "  ['it', 'O'],\n",
       "  ['could', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['organization', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Analyst', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['When', 'O'],\n",
       "  ['it', 'O'],\n",
       "  ['’s', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['organization', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['do', 'O'],\n",
       "  ['you', 'O'],\n",
       "  ['always', 'O'],\n",
       "  ['need', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['know', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['contact', 'O'],\n",
       "  ['?', 'O']],\n",
       " [['AP', 'O'], [':', 'O']],\n",
       " [['Yes', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['sometimes', 'O'],\n",
       "  ['there', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['more', 'O'],\n",
       "  ['than', 'O'],\n",
       "  ['one', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['For', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['client', 'B-class'],\n",
       "  ['or', 'O'],\n",
       "  ['representative', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['organization', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['I', 'O'],\n",
       "  ['need', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['write', 'O'],\n",
       "  ['down', 'O'],\n",
       "  ['their', 'O'],\n",
       "  ['full', 'B-attr'],\n",
       "  ['name', 'I-attr'],\n",
       "  ['and', 'O'],\n",
       "  ['how', 'O'],\n",
       "  ['they', 'O'],\n",
       "  ['prefer', 'O'],\n",
       "  ['their', 'O'],\n",
       "  ['honorific', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['Mr.', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['Ms.', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['Mrs.', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['Dr.', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['etc', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['And', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['course', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['their', 'O'],\n",
       "  ['email', 'B-attr'],\n",
       "  ['address', 'I-attr'],\n",
       "  [',', 'O'],\n",
       "  ['phone', 'B-attr'],\n",
       "  ['number', 'I-attr'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['postal', 'B-attr'],\n",
       "  ['address', 'I-attr'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['sometimes', 'O'],\n",
       "  ['we', 'O'],\n",
       "  ['have', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['primary', 'O'],\n",
       "  ['mailing', 'O'],\n",
       "  ['address', 'O'],\n",
       "  ['that', 'O'],\n",
       "  ['could', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['different', 'O'],\n",
       "  ['from', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['billing', 'B-attr'],\n",
       "  ['address', 'I-attr'],\n",
       "  ['.', 'O']],\n",
       " [['Analyst', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['Could', 'O'],\n",
       "  ['you', 'O'],\n",
       "  ['have', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['situation', 'O'],\n",
       "  ['where', 'O'],\n",
       "  ['multiple', 'O'],\n",
       "  ['people', 'O'],\n",
       "  ['have', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['same', 'O'],\n",
       "  ['address', 'B-attr'],\n",
       "  ['?', 'O']],\n",
       " [['AP', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['This', 'O'],\n",
       "  ['does', 'O'],\n",
       "  ['happen', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['example', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['when', 'O'],\n",
       "  ['we', 'O'],\n",
       "  ['contact', 'O'],\n",
       "  ['different', 'O'],\n",
       "  ['employees', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['same', 'O'],\n",
       "  ['office', 'B-class'],\n",
       "  ['.', 'O']],\n",
       " [['Analyst', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['What', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['your', 'O'],\n",
       "  ['other', 'O'],\n",
       "  ['responsibilities', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['apart', 'O'],\n",
       "  ['from', 'O'],\n",
       "  ['creating', 'O'],\n",
       "  ['cases', 'B-class'],\n",
       "  ['?', 'O']],\n",
       " [['We', 'O'],\n",
       "  ['have', 'O'],\n",
       "  ['had', 'O'],\n",
       "  ['several', 'O'],\n",
       "  ['situations', 'O'],\n",
       "  ['where', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['due', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['incorrect', 'O'],\n",
       "  ['address', 'O'],\n",
       "  ['format', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['client', 'B-class'],\n",
       "  ['did', 'O'],\n",
       "  ['not', 'O'],\n",
       "  ['receive', 'O'],\n",
       "  ['correspondence', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['AP', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['As', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['case', 'O'],\n",
       "  ['progresses', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['I', 'O'],\n",
       "  ['need', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['record', 'O'],\n",
       "  ['all', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['individuals', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['organizations', 'O'],\n",
       "  ['that', 'O'],\n",
       "  ['take', 'O'],\n",
       "  ['part', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['case', 'O'],\n",
       "  ['activities', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['specific', 'O'],\n",
       "  ['role', 'O'],\n",
       "  ['they', 'O'],\n",
       "  ['play', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Analyst', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['Is', 'O'],\n",
       "  ['it', 'O'],\n",
       "  ['possible', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['individual', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['organization', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['participate', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['multiple', 'O'],\n",
       "  ['actions', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['events', 'B-class'],\n",
       "  ['in', 'O'],\n",
       "  ['different', 'O'],\n",
       "  ['cases', 'B-class'],\n",
       "  ['?', 'O']],\n",
       " [['AP', 'O'], [':', 'O']],\n",
       " [['Yes', 'O'], ['.', 'O']],\n",
       " [['Not', 'O'],\n",
       "  ['only', 'O'],\n",
       "  ['that', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['but', 'O'],\n",
       "  ['some', 'O'],\n",
       "  ['may', 'O'],\n",
       "  ['play', 'O'],\n",
       "  ['different', 'O'],\n",
       "  ['roles', 'O'],\n",
       "  ['within', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['same', 'O'],\n",
       "  ['case', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['For', 'O'],\n",
       "  ['example', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['same', 'O'],\n",
       "  ['party', 'O'],\n",
       "  ['can', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['both', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['defendant', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['witness', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['same', 'O'],\n",
       "  ['case', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Analyst', 'O'], [':', 'O']],\n",
       " [['So', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['what', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['these', 'O'],\n",
       "  ['different', 'O'],\n",
       "  ['types', 'B-attr'],\n",
       "  ['of', 'I-attr'],\n",
       "  ['roles', 'I-attr'],\n",
       "  ['a', 'O'],\n",
       "  ['party', 'O'],\n",
       "  ['can', 'O'],\n",
       "  ['play', 'O'],\n",
       "  ['?', 'O']],\n",
       " [['AP', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['Plaintiff', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['witness', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['defendant', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['judge', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['expert', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['some', 'O'],\n",
       "  ['field', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['attorney', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Analyst', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['Can', 'O'],\n",
       "  ['your', 'O'],\n",
       "  ['firm', 'O'],\n",
       "  ['’s', 'O'],\n",
       "  ['attorneys', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['judges', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['considered', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['parties', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['case', 'O'],\n",
       "  ['?', 'O']],\n",
       " [['Analyst', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['Can', 'O'],\n",
       "  ['you', 'O'],\n",
       "  ['give', 'O'],\n",
       "  ['me', 'O'],\n",
       "  ['some', 'O'],\n",
       "  ['examples', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['this', 'O'],\n",
       "  ['?', 'O']],\n",
       " [['AP', 'O'], [':', 'O']],\n",
       " [['Absolutely', 'O'], ['.', 'O']],\n",
       " [['And', 'O'],\n",
       "  ['I', 'O'],\n",
       "  ['must', 'O'],\n",
       "  ['record', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['information', 'O'],\n",
       "  ['about', 'O'],\n",
       "  ['their', 'O'],\n",
       "  ['involvement', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['well', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Analyst', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['Please', 'O'],\n",
       "  ['tell', 'O'],\n",
       "  ['me', 'O'],\n",
       "  ['about', 'O'],\n",
       "  ['events', 'B-class'],\n",
       "  ['that', 'O'],\n",
       "  ['occur', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['What', 'O'],\n",
       "  ['information', 'O'],\n",
       "  ['do', 'O'],\n",
       "  ['you', 'O'],\n",
       "  ['record', 'O'],\n",
       "  ['?', 'O']],\n",
       " [['AP', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['All', 'O'],\n",
       "  ['attorneys', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['legal', 'O'],\n",
       "  ['assistants', 'O'],\n",
       "  ['record', 'O'],\n",
       "  ['their', 'O'],\n",
       "  ['own', 'O'],\n",
       "  ['activities', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['which', 'O'],\n",
       "  ['include', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['date', 'B-attr'],\n",
       "  ['and', 'O'],\n",
       "  ['time', 'O'],\n",
       "  ['when', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['activity', 'O'],\n",
       "  ['occurred', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['short', 'O'],\n",
       "  ['description', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['duration', 'B-attr'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['case', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['witnesses', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['defendants', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['judges', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['list', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['who', 'O'],\n",
       "  ['was', 'O'],\n",
       "  ['involved', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['We', 'O'],\n",
       "  ['also', 'O'],\n",
       "  ['need', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['indicate', 'O'],\n",
       "  ['if', 'O'],\n",
       "  ['this', 'O'],\n",
       "  ['event', 'B-class'],\n",
       "  ['is', 'O'],\n",
       "  ['billable', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['not', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Analyst', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['Is', 'O'],\n",
       "  ['there', 'O'],\n",
       "  ['anything', 'O'],\n",
       "  ['else', 'O'],\n",
       "  ['you', 'O'],\n",
       "  ['record', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['cases', 'B-class'],\n",
       "  ['?', 'O']],\n",
       " [['AP', 'O'], [':', 'O']],\n",
       " [['Yes', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['we', 'O'],\n",
       "  ['need', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['know', 'O'],\n",
       "  ['which', 'O'],\n",
       "  ['documents', 'O'],\n",
       "  ['were', 'O'],\n",
       "  ['used', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['case', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['AP', 'O'], [':', 'O']],\n",
       " [['Yes', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['one', 'O'],\n",
       "  ['happened', 'O'],\n",
       "  ['recently', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Sometimes', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['addresses', 'B-attr'],\n",
       "  ['start', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['house', 'B-attr'],\n",
       "  ['name', 'I-attr'],\n",
       "  ['or', 'O'],\n",
       "  ['number', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['but', 'O'],\n",
       "  ['some', 'O'],\n",
       "  ['overseas', 'O'],\n",
       "  ['clients', 'B-class'],\n",
       "  ['put', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['city', 'B-attr'],\n",
       "  ['or', 'O'],\n",
       "  ['town', 'O'],\n",
       "  ['first', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Imagine', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['confusion', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['sending', 'O'],\n",
       "  ['something', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['Paris', 'O'],\n",
       "  ['which', 'O'],\n",
       "  ['we', 'O'],\n",
       "  ['thought', 'O'],\n",
       "  ['was', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['city', 'O'],\n",
       "  ['but', 'O'],\n",
       "  ['was', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['fact', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['house', 'B-attr'],\n",
       "  ['name', 'I-attr'],\n",
       "  ['!', 'O']],\n",
       " [['The', 'O'],\n",
       "  ['other', 'O'],\n",
       "  ['issue', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['that', 'O'],\n",
       "  ['overseas', 'O'],\n",
       "  ['zip', 'O'],\n",
       "  ['codes', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['postal', 'B-attr'],\n",
       "  ['codes', 'I-attr'],\n",
       "  [',', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['they', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['sometimes', 'O'],\n",
       "  ['called', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['not', 'O'],\n",
       "  ['always', 'O'],\n",
       "  ['numeric', 'O'],\n",
       "  ['—', 'O'],\n",
       "  ['they', 'O'],\n",
       "  ['can', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['combination', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['numbers', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['letters', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Analyst', 'O'],\n",
       "  [':', 'O'],\n",
       "  ['Tell', 'O'],\n",
       "  ['me', 'O'],\n",
       "  ['about', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['process', 'O'],\n",
       "  ['when', 'O'],\n",
       "  ['you', 'O'],\n",
       "  ['take', 'O'],\n",
       "  ['on', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['new', 'O'],\n",
       "  ['client', 'B-class'],\n",
       "  ['.', 'O']],\n",
       " [['The', 'O'],\n",
       "  ['Right', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['Way', 'O'],\n",
       "  ['Rental', 'O'],\n",
       "  ['Truck', 'O'],\n",
       "  ['Company', 'O'],\n",
       "  ['rents', 'O'],\n",
       "  ['small', 'O'],\n",
       "  ['moving', 'O'],\n",
       "  ['trucks', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['trailers', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['local', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['one', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['way', 'O'],\n",
       "  ['usage', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['We', 'O'],\n",
       "  ['have', 'O'],\n",
       "  ['347', 'O'],\n",
       "  ['rental', 'O'],\n",
       "  ['offices', 'B-class'],\n",
       "  ['across', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['western', 'O'],\n",
       "  ['United', 'O'],\n",
       "  ['States', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['office', 'B-class'],\n",
       "  ['is', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['home', 'B-class'],\n",
       "  ['office', 'I-class'],\n",
       "  ['for', 'O'],\n",
       "  ['some', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['our', 'O'],\n",
       "  ['vehicles', 'B-class'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['vehicle', 'B-class'],\n",
       "  ['is', 'O'],\n",
       "  ['based', 'O'],\n",
       "  ['out', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['single', 'O'],\n",
       "  ['home', 'B-class'],\n",
       "  ['office', 'I-class'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['vehicle', 'B-class'],\n",
       "  ['has', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['vehicle', 'B-attr'],\n",
       "  ['i', 'I-attr'],\n",
       "  ['d', 'I-attr'],\n",
       "  [',', 'O'],\n",
       "  ['state', 'B-attr'],\n",
       "  ['of', 'I-attr'],\n",
       "  ['registration', 'I-attr'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['license', 'B-attr'],\n",
       "  ['plate', 'I-attr'],\n",
       "  ['registration', 'I-attr'],\n",
       "  ['number', 'I-attr'],\n",
       "  ['.', 'O']],\n",
       " [['We', 'O'],\n",
       "  ['have', 'O'],\n",
       "  ['five', 'O'],\n",
       "  ['different', 'O'],\n",
       "  ['types', 'B-attr'],\n",
       "  ['of', 'O'],\n",
       "  ['vehicles', 'B-class'],\n",
       "  [':', 'O'],\n",
       "  ['36', 'O'],\n",
       "  ['trucks', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['24', 'O'],\n",
       "  ['’', 'O'],\n",
       "  ['trucks', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['10', 'O'],\n",
       "  ['’', 'O'],\n",
       "  ['trucks', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['8', 'O'],\n",
       "  ['’', 'O'],\n",
       "  ['covered', 'O'],\n",
       "  ['trailers', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['6', 'O'],\n",
       "  ['’', 'O'],\n",
       "  ['open', 'O'],\n",
       "  ['trailers', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Yes', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['we', 'O'],\n",
       "  ['do', 'O'],\n",
       "  ['have', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['vehicle', 'B-attr'],\n",
       "  ['type', 'I-attr'],\n",
       "  ['code', 'I-attr'],\n",
       "  ['.', 'O']],\n",
       " [['For', 'O'],\n",
       "  ['all', 'O'],\n",
       "  ['our', 'O'],\n",
       "  ['vehicles', 'B-class'],\n",
       "  [',', 'O'],\n",
       "  ['we', 'O'],\n",
       "  ['need', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['track', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['last', 'O'],\n",
       "  ['maintenance', 'O'],\n",
       "  ['date', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['expiration', 'O'],\n",
       "  ['date', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['its', 'O'],\n",
       "  ['registration', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['For', 'O'],\n",
       "  ['our', 'O'],\n",
       "  ['trucks', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['we', 'O'],\n",
       "  ['need', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['know', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['current', 'O'],\n",
       "  ['odometer', 'O'],\n",
       "  ['reading', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['gas', 'O'],\n",
       "  ['tank', 'O'],\n",
       "  ['capacity', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['whether', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['not', 'O'],\n",
       "  ['it', 'O'],\n",
       "  ['has', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['working', 'O'],\n",
       "  ['radio', 'B-class'],\n",
       "  ['.', 'O']],\n",
       " [['For', 'O'],\n",
       "  ['long', 'O'],\n",
       "  ['moves', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['customers', 'B-class'],\n",
       "  ['really', 'O'],\n",
       "  ['prefer', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['radio', 'B-class'],\n",
       "  ['.', 'O']],\n",
       " [['We', 'O'],\n",
       "  ['log', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['current', 'O'],\n",
       "  ['mileage', 'O'],\n",
       "  ['just', 'O'],\n",
       "  ['before', 'O'],\n",
       "  ['we', 'O'],\n",
       "  ['rent', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['truck', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['then', 'O'],\n",
       "  ['again', 'O'],\n",
       "  ['when', 'O'],\n",
       "  ['it', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['returned', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Most', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['our', 'O'],\n",
       "  ['rental', 'O'],\n",
       "  ['agreements', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['individual', 'O'],\n",
       "  ['customers', 'B-class'],\n",
       "  [',', 'O'],\n",
       "  ['but', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['rental', 'O'],\n",
       "  ['agreement', 'O'],\n",
       "  ['can', 'O'],\n",
       "  ['either', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['individual', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['company', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['We', 'O'],\n",
       "  ['do', 'O'],\n",
       "  ['rent', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['small', 'O'],\n",
       "  ['percentage', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['our', 'O'],\n",
       "  ['trucks', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['companies', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Our', 'O'],\n",
       "  ['rental', 'B-attr'],\n",
       "  ['stock', 'I-attr'],\n",
       "  ['includes', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['total', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['5,78', 'O'],\n",
       "  ['vehicles', 'B-class'],\n",
       "  ['including', 'O'],\n",
       "  ['various', 'O'],\n",
       "  ['types', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['trucks', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['trailers', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['We', 'O'],\n",
       "  ['assign', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['company', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['identifying', 'O'],\n",
       "  ['company', 'O'],\n",
       "  ['number', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['track', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['company', 'O'],\n",
       "  ['’s', 'O'],\n",
       "  ['name', 'B-attr'],\n",
       "  ['and', 'O'],\n",
       "  ['address', 'B-attr'],\n",
       "  ['.', 'O']],\n",
       " [['No', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['we', 'O'],\n",
       "  ['do', 'O'],\n",
       "  ['n’t', 'O'],\n",
       "  ['need', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['worry', 'O'],\n",
       "  ['about', 'O'],\n",
       "  ['any', 'O'],\n",
       "  ['additional', 'O'],\n",
       "  ['information', 'O'],\n",
       "  ['about', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['company', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Our', 'O'],\n",
       "  ['corporate', 'O'],\n",
       "  ['sales', 'B-class'],\n",
       "  ['group', 'I-class'],\n",
       "  ['handles', 'O'],\n",
       "  ['all', 'O'],\n",
       "  ['that', 'O'],\n",
       "  ['information', 'O'],\n",
       "  ['separately', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['For', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['individual', 'O'],\n",
       "  ['customer', 'B-class'],\n",
       "  [',', 'O'],\n",
       "  ['we', 'O'],\n",
       "  ['record', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['customer', 'B-class'],\n",
       "  ['’s', 'O'],\n",
       "  ['name', 'B-attr'],\n",
       "  [',', 'O'],\n",
       "  ['home', 'O'],\n",
       "  ['phone', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['address', 'B-attr'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['driver', 'B-class'],\n",
       "  ['’s', 'O'],\n",
       "  ['license', 'B-attr'],\n",
       "  ['state', 'I-attr'],\n",
       "  [',', 'O'],\n",
       "  ['number', 'B-attr'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['expiration', 'O'],\n",
       "  ['date', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['We', 'O'],\n",
       "  ['like', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['keep', 'O'],\n",
       "  ['track', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['all', 'O'],\n",
       "  ['our', 'O'],\n",
       "  ['customers', 'B-class'],\n",
       "  ['.', 'O']],\n",
       " [['If', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['customer', 'B-class'],\n",
       "  ['damaged', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['vehicle', 'B-class'],\n",
       "  [',', 'O'],\n",
       "  ['abandoned', 'O'],\n",
       "  ['it', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['did', 'O'],\n",
       "  ['n’t', 'O'],\n",
       "  ['fully', 'O'],\n",
       "  ['pay', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['bill', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['then', 'O'],\n",
       "  ['we', 'O'],\n",
       "  ['tag', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['customer', 'B-class'],\n",
       "  ['as', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['poor', 'O'],\n",
       "  ['risk', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['wo', 'O'],\n",
       "  ['n’t', 'O'],\n",
       "  ['rent', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['that', 'O'],\n",
       "  ['customer', 'B-class'],\n",
       "  ['again', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['We', 'O'],\n",
       "  ['only', 'O'],\n",
       "  ['allow', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['single', 'O'],\n",
       "  ['individual', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['company', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['given', 'O'],\n",
       "  ['rental', 'O'],\n",
       "  ['agreement', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['we', 'O'],\n",
       "  ['write', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['separate', 'O'],\n",
       "  ['rental', 'O'],\n",
       "  ['agreement', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['vehicle', 'B-class'],\n",
       "  ['.', 'O']],\n",
       " [['Yes', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['we', 'O'],\n",
       "  ['do', 'O'],\n",
       "  ['have', 'O'],\n",
       "  ['customers', 'B-class'],\n",
       "  ['rent', 'O'],\n",
       "  ['two', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['more', 'O'],\n",
       "  ['vehicles', 'B-class'],\n",
       "  ['at', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['same', 'O'],\n",
       "  ['time', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['rental', 'B-class'],\n",
       "  ['agreement', 'I-class'],\n",
       "  ['is', 'O'],\n",
       "  ['identified', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['originating', 'O'],\n",
       "  ['rental', 'O'],\n",
       "  ['office', 'B-attr'],\n",
       "  ['number', 'I-attr'],\n",
       "  ['and', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['rental', 'O'],\n",
       "  ['agreement', 'O'],\n",
       "  ['number', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['We', 'O'],\n",
       "  ['also', 'O'],\n",
       "  ['need', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['track', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['rental', 'O'],\n",
       "  ['date', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['anticipated', 'O'],\n",
       "  ['duration', 'B-attr'],\n",
       "  ['of', 'I-attr'],\n",
       "  ['the', 'I-attr'],\n",
       "  ['rental', 'I-attr'],\n",
       "  [',', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['originating', 'O'],\n",
       "  ['rental', 'B-class'],\n",
       "  ['office', 'I-class'],\n",
       "  [',', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['drop', 'B-class'],\n",
       "  ['-', 'I-class'],\n",
       "  ['off', 'I-class'],\n",
       "  ['rental', 'I-class'],\n",
       "  ['office', 'I-class'],\n",
       "  [',', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['amount', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['deposit', 'O'],\n",
       "  ['paid', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['quoted', 'O'],\n",
       "  ['daily', 'O'],\n",
       "  ['rental', 'O'],\n",
       "  ['rate', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['quoted', 'O'],\n",
       "  ['rate', 'O'],\n",
       "  ['per', 'O'],\n",
       "  ['mile', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['We', 'O'],\n",
       "  ['need', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['implement', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['system', 'B-class'],\n",
       "  ['to', 'O'],\n",
       "  ['track', 'O'],\n",
       "  ['our', 'O'],\n",
       "  ['rental', 'O'],\n",
       "  ['agreements', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['our', 'O'],\n",
       "  ['vehicle', 'O'],\n",
       "  ['assignments', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Of', 'O'],\n",
       "  ['course', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['trailers', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['there', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['n’t', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['mileage', 'B-attr'],\n",
       "  ['charge', 'I-attr'],\n",
       "  ['.', 'O']],\n",
       " [['No', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['we', 'O'],\n",
       "  ['do', 'O'],\n",
       "  ['n’t', 'O'],\n",
       "  ['need', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['automate', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['financial', 'O'],\n",
       "  ['side', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['our', 'O'],\n",
       "  ['business', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['just', 'O'],\n",
       "  ['our', 'O'],\n",
       "  ['rental', 'O'],\n",
       "  ['agreement', 'O'],\n",
       "  ['tracking', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['vehicle', 'O'],\n",
       "  ['assignment', 'O'],\n",
       "  ['functions', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['rental', 'B-class'],\n",
       "  ['office', 'I-class'],\n",
       "  ['rents', 'O'],\n",
       "  ['vehicles', 'O'],\n",
       "  ['that', 'O'],\n",
       "  ['they', 'O'],\n",
       "  ['have', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['stock', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['customers', 'B-class'],\n",
       "  ['ready', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['take', 'O'],\n",
       "  ['possession', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['vehicle', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['We', 'O'],\n",
       "  ['do', 'O'],\n",
       "  ['n’t', 'O'],\n",
       "  ['take', 'O'],\n",
       "  ['reservations', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['speculate', 'O'],\n",
       "  ['on', 'O'],\n",
       "  ['when', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['customer', 'B-class'],\n",
       "  ['will', 'O'],\n",
       "  ['return', 'O'],\n",
       "  ['rented', 'O'],\n",
       "  ['vehicles', 'B-class'],\n",
       "  ['.', 'O']],\n",
       " [['The', 'O'],\n",
       "  ['central', 'B-class'],\n",
       "  ['office', 'I-class'],\n",
       "  ['oversees', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['vehicle', 'O'],\n",
       "  ['distribution', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['directs', 'O'],\n",
       "  ['transfers', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['vehicles', 'B-class'],\n",
       "  ['from', 'O'],\n",
       "  ['one', 'O'],\n",
       "  ['rental', 'B-class'],\n",
       "  ['office', 'I-class'],\n",
       "  ['to', 'O'],\n",
       "  ['another', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['rental', 'B-class'],\n",
       "  ['office', 'I-class'],\n",
       "  ['has', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['office', 'B-attr'],\n",
       "  ['name', 'I-attr'],\n",
       "  ['like', 'O'],\n",
       "  ['“', 'O'],\n",
       "  ['Littleton', 'O'],\n",
       "  ['Right', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['Way', 'O'],\n",
       "  ['”', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['office', 'B-class'],\n",
       "  ['also', 'O'],\n",
       "  ['has', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['unique', 'O'],\n",
       "  ['three', 'B-attr'],\n",
       "  ['digit', 'I-attr'],\n",
       "  ['office', 'I-attr'],\n",
       "  ['number', 'I-attr'],\n",
       "  ['.', 'O']],\n",
       " [['We', 'O'],\n",
       "  ['also', 'O'],\n",
       "  ['keep', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['office', 'B-class'],\n",
       "  ['’s', 'O'],\n",
       "  ['address', 'B-attr'],\n",
       "  ['.', 'O']],\n",
       " [['Romano', 'O'],\n",
       "  [\"'s\", 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['finest', 'O'],\n",
       "  ['Italian', 'O'],\n",
       "  ['restaurant', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['city', 'B-attr'],\n",
       "  ['.', 'O']],\n",
       " [['Unless', 'O'],\n",
       "  ['you', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['celebrity', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['good', 'O'],\n",
       "  ['friend', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['Romano', 'O'],\n",
       "  ['you', 'O'],\n",
       "  ['will', 'O'],\n",
       "  ['need', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['reservation', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['table', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['identified', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['unique', 'B-attr'],\n",
       "  ['table', 'I-attr'],\n",
       "  ['number', 'I-attr'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['tables', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['further', 'O'],\n",
       "  ['described', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['unique', 'O'],\n",
       "  ['free', 'O'],\n",
       "  ['form', 'O'],\n",
       "  ['description', 'O'],\n",
       "  ['such', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  ['located', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['North', 'O'],\n",
       "  ['window', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  ['located', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['front', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['fountain', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['kitchen', 'O'],\n",
       "  ['door', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['table', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['classified', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['2', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['person', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['4', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['person', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['6', 'O'],\n",
       "  ['-', 'O'],\n",
       "  ['person', 'O'],\n",
       "  ['table', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['When', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['reservation', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['made', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['Romano', 'O'],\n",
       "  ['associates', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['specific', 'O'],\n",
       "  ['number', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['reservation', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['A', 'O'],\n",
       "  ['table', 'O'],\n",
       "  ['can', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['utilized', 'O'],\n",
       "  ['many', 'O'],\n",
       "  ['times', 'O'],\n",
       "  ['over', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['evening', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['many', 'O'],\n",
       "  ['reservations', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Romano', 'O'],\n",
       "  ['tends', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['overbook', 'O'],\n",
       "  ['tables', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Therefore', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['there', 'O'],\n",
       "  ['can', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['overlapping', 'O'],\n",
       "  ['table', 'O'],\n",
       "  ['reservations', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['The', 'O'],\n",
       "  ['management', 'O'],\n",
       "  ['structure', 'O'],\n",
       "  ['at', 'O'],\n",
       "  ['Romano', 'O'],\n",
       "  [\"'s\", 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['hierarchical', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['There', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['several', 'O'],\n",
       "  ['restaurant', 'O'],\n",
       "  ['managers', 'O'],\n",
       "  ['who', 'O'],\n",
       "  ['report', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['Romano', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['The', 'O'],\n",
       "  ['managers', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['responsible', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['managing', 'O'],\n",
       "  ['the', 'O'],\n",
       "  [\"Maitre'd\", 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['chefs', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['well', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['ensuring', 'O'],\n",
       "  ['that', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['guests', 'O'],\n",
       "  ['have', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['pleasant', 'O'],\n",
       "  ['dining', 'O'],\n",
       "  ['experience', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['A', 'O'],\n",
       "  ['reservation', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['made', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['specific', 'O'],\n",
       "  ['time', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['date', 'B-attr'],\n",
       "  ['and', 'I-attr'],\n",
       "  ['number', 'I-attr'],\n",
       "  ['of', 'O'],\n",
       "  ['people', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['The', 'O'],\n",
       "  [\"Maitre'd\", 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['responsible', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['managing', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['waiters', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['bartenders', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['bus', 'O'],\n",
       "  ['personnel', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['The', 'O'],\n",
       "  ['Chefs', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['responsible', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['managing', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['cooks', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['dishwashers', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['person', 'B-class'],\n",
       "  ['working', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['Romano', 'O'],\n",
       "  [\"'s\", 'O'],\n",
       "  ['must', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['classified', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['either', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['manager', 'O'],\n",
       "  [',', 'O'],\n",
       "  [\"Maitre'd\", 'O'],\n",
       "  [',', 'O'],\n",
       "  ['waiter', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['bartender', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['chef', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['cook', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['bus', 'O'],\n",
       "  ['person', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['dishwasher', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Additional', 'O'],\n",
       "  ['information', 'O'],\n",
       "  ['maintained', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['Romano', 'O'],\n",
       "  [\"'s\", 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['person', 'B-class'],\n",
       "  ['includes', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['persons', 'B-attr'],\n",
       "  ['name', 'I-attr'],\n",
       "  [',', 'O'],\n",
       "  ['date', 'B-attr'],\n",
       "  ['of', 'I-attr'],\n",
       "  ['birth', 'I-attr'],\n",
       "  ['and', 'O'],\n",
       "  ['drivers', 'O'],\n",
       "  ['license', 'O'],\n",
       "  ['number', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['When', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['reservation', 'O'],\n",
       "  ['party', 'O'],\n",
       "  ['arrives', 'O'],\n",
       "  ['at', 'O'],\n",
       "  ['Romano', 'O'],\n",
       "  [\"'s\", 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['reservation', 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['assigned', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['one', 'O'],\n",
       "  ['waiter', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['A', 'O'],\n",
       "  ['waiter', 'O'],\n",
       "  ['can', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['assigned', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['many', 'O'],\n",
       "  ['reservations', 'O'],\n",
       "  ['during', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['course', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['evening', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['The', 'O'],\n",
       "  ['menu', 'O'],\n",
       "  ['at', 'O'],\n",
       "  ['Romano', 'O'],\n",
       "  [\"'s\", 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['exquisite', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['There', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['many', 'O'],\n",
       "  ['exciting', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['exotic', 'O'],\n",
       "  ['items', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['menu', 'B-class'],\n",
       "  ['item', 'I-class'],\n",
       "  ['is', 'O'],\n",
       "  ['identified', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['unique', 'B-attr'],\n",
       "  ['menu', 'I-attr'],\n",
       "  ['item', 'I-attr'],\n",
       "  ['number', 'I-attr'],\n",
       "  ['.', 'O']],\n",
       " [['Information', 'O'],\n",
       "  ['maintained', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['Romano', 'O'],\n",
       "  [\"'s\", 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['menu', 'B-class'],\n",
       "  ['item', 'I-class'],\n",
       "  ['includes', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['item', 'B-attr'],\n",
       "  ['description', 'I-attr'],\n",
       "  ['of', 'O'],\n",
       "  ['(', 'O'],\n",
       "  ['e.g.', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  ['chicken', 'O'],\n",
       "  ['marsala', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  ['fish', 'O'],\n",
       "  ['soup', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  ['endive', 'O'],\n",
       "  ['salad\",\"1988', 'O'],\n",
       "  ['Merlot', 'O'],\n",
       "  ['wine', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['etc', 'O'],\n",
       "  ['.', 'O'],\n",
       "  [')', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['item', 'O'],\n",
       "  ['prep', 'O'],\n",
       "  ['time', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['The', 'O'],\n",
       "  ['reservation', 'O'],\n",
       "  ['also', 'O'],\n",
       "  ['captures', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['name', 'B-attr'],\n",
       "  ['and', 'O'],\n",
       "  ['phone', 'B-attr'],\n",
       "  ['number', 'I-attr'],\n",
       "  ['of', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['person', 'O'],\n",
       "  ['making', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['reservation', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['menu', 'B-class'],\n",
       "  ['item', 'I-class'],\n",
       "  ['is', 'O'],\n",
       "  ['classified', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['Romano', 'O'],\n",
       "  [\"'s\", 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  ['appetizer', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  ['entree', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  ['dessert', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  ['beverage', 'O'],\n",
       "  ['\"', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['The', 'O'],\n",
       "  ['price', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['menu', 'B-class'],\n",
       "  ['item', 'I-class'],\n",
       "  ['can', 'O'],\n",
       "  ['vary', 'O'],\n",
       "  ['based', 'O'],\n",
       "  ['on', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['time', 'B-attr'],\n",
       "  ['of', 'I-attr'],\n",
       "  ['day', 'I-attr'],\n",
       "  ['.', 'O']],\n",
       " [['For', 'O'],\n",
       "  ['example', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['some', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['menu', 'O'],\n",
       "  ['items', 'O'],\n",
       "  ['have', 'O'],\n",
       "  ['different', 'O'],\n",
       "  ['lunch', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['dinner', 'B-attr'],\n",
       "  ['prices', 'I-attr'],\n",
       "  ['.', 'O']],\n",
       " [['Some', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['menu', 'O'],\n",
       "  ['items', 'O'],\n",
       "  ['change', 'O'],\n",
       "  ['prices', 'B-attr'],\n",
       "  ['for', 'O'],\n",
       "  ['happy', 'O'],\n",
       "  ['hour', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['In', 'O'],\n",
       "  ['order', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['calculate', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['check', 'O'],\n",
       "  ['at', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['end', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['dinner', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['waiter', 'O'],\n",
       "  ['maintains', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['list', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['reservation', 'B-attr'],\n",
       "  ['number', 'I-attr'],\n",
       "  [',', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['menu', 'O'],\n",
       "  ['items', 'O'],\n",
       "  ['ordered', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['time', 'O'],\n",
       "  ['that', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['menu', 'O'],\n",
       "  ['item', 'O'],\n",
       "  ['was', 'O'],\n",
       "  ['ordered', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['In', 'O'],\n",
       "  ['other', 'O'],\n",
       "  ['words', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['each', 'O'],\n",
       "  ['reservation', 'B-class'],\n",
       "  ['can', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['associated', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['many', 'O'],\n",
       "  ['menu', 'O'],\n",
       "  ['items', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['menu', 'O'],\n",
       "  ['item', 'O'],\n",
       "  ['can', 'O'],\n",
       "  ['be', 'O'],\n",
       "  ['associated', 'O'],\n",
       "  ['with', 'O'],\n",
       "  ['many', 'O'],\n",
       "  ['reservations', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['In', 'O'],\n",
       "  ['addition', 'O'],\n",
       "  ['to', 'O'],\n",
       "  ['menu', 'O'],\n",
       "  ['items', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['Romano', 'O'],\n",
       "  [\"'s\", 'O'],\n",
       "  ['maintains', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['list', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['food', 'O'],\n",
       "  ['items', 'O'],\n",
       "  ['that', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['utilized', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['restaurant', 'O'],\n",
       "  ['such', 'O'],\n",
       "  ['as', 'O'],\n",
       "  ['chicken', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['mushrooms', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['bread', 'O'],\n",
       "  ['sticks', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['red', 'O'],\n",
       "  ['sauce', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['cream', 'O'],\n",
       "  ['sauce', 'O'],\n",
       "  [',', 'O'],\n",
       "  ['etc', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Food', 'O'],\n",
       "  ['items', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['utilized', 'O'],\n",
       "  ['in', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['preparation', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['menu', 'O'],\n",
       "  ['items', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['food', 'B-class'],\n",
       "  ['item', 'I-class'],\n",
       "  ['is', 'O'],\n",
       "  ['identified', 'O'],\n",
       "  ['by', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['unique', 'B-attr'],\n",
       "  ['food', 'I-attr'],\n",
       "  ['item', 'I-attr'],\n",
       "  ['number', 'I-attr'],\n",
       "  ['.', 'O']],\n",
       " [['Each', 'O'],\n",
       "  ['reservation', 'B-class'],\n",
       "  ['is', 'O'],\n",
       "  ['assigned', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['unique', 'O'],\n",
       "  ['reservation', 'B-attr'],\n",
       "  ['number', 'I-attr'],\n",
       "  ['.', 'O']],\n",
       " [['There', 'O'],\n",
       "  ['are', 'O'],\n",
       "  ['two', 'O'],\n",
       "  ['categories', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['reservations', 'O'],\n",
       "  ['at', 'O'],\n",
       "  ['Romano', 'O'],\n",
       "  [\"'s\", 'O'],\n",
       "  [':', 'O'],\n",
       "  ['individual', 'O'],\n",
       "  ['reservations', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['banquet', 'O'],\n",
       "  ['reservations', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Additional', 'O'],\n",
       "  ['reservation', 'O'],\n",
       "  ['information', 'O'],\n",
       "  ['captured', 'O'],\n",
       "  ['when', 'O'],\n",
       "  ['an', 'O'],\n",
       "  ['individual', 'O'],\n",
       "  ['makes', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['reservation', 'O'],\n",
       "  ['includes', 'O'],\n",
       "  ['seating', 'O'],\n",
       "  ['preference', 'O'],\n",
       "  ['(', 'O'],\n",
       "  ['inside', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['patio', 'O'],\n",
       "  [')', 'O'],\n",
       "  ['and', 'O'],\n",
       "  ['smoking', 'O'],\n",
       "  ['preference', 'O'],\n",
       "  ['(', 'O'],\n",
       "  ['smoking', 'O'],\n",
       "  ['or', 'O'],\n",
       "  ['nonsmoking', 'O'],\n",
       "  [')', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Additional', 'O'],\n",
       "  ['reservation', 'O'],\n",
       "  ['information', 'O'],\n",
       "  ['captured', 'O'],\n",
       "  ['for', 'O'],\n",
       "  ['banquet', 'O'],\n",
       "  ['reservations', 'O'],\n",
       "  ['includes', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['group', 'B-attr'],\n",
       "  ['name', 'I-attr'],\n",
       "  ['and', 'O'],\n",
       "  ['the', 'O'],\n",
       "  ['method', 'O'],\n",
       "  ['of', 'O'],\n",
       "  ['payment', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Seating', 'O'],\n",
       "  ['at', 'O'],\n",
       "  ['Romano', 'O'],\n",
       "  [\"'s\", 'O'],\n",
       "  ['is', 'O'],\n",
       "  ['limited', 'O'],\n",
       "  ['.', 'O']],\n",
       " [['Romano', 'O'],\n",
       "  [\"'s\", 'O'],\n",
       "  ['has', 'O'],\n",
       "  ['a', 'O'],\n",
       "  ['fixed', 'B-attr'],\n",
       "  ['number', 'I-attr'],\n",
       "  ['of', 'I-attr'],\n",
       "  ['tables', 'I-attr'],\n",
       "  ['.', 'O']]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[[word['word'], pred] for word, pred in zip(sent, predictions)] for sent, predictions in zip(X_test, y_pred)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default model + fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-0e31d1263710>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train = np.array([sent2features(s, embedding = True) for s in train_sentences])\n",
      "<ipython-input-42-0e31d1263710>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test = np.array([sent2features(s, embedding = True) for s in validation_sentences])\n",
      "<ipython-input-42-0e31d1263710>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_train = np.array([sent2labels(s) for s in train_sentences])\n",
      "<ipython-input-42-0e31d1263710>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_test = np.array([sent2labels(s) for s in validation_sentences])\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([sent2features(s, embedding = True) for s in train_sentences])\n",
    "X_test = np.array([sent2features(s, embedding = True) for s in validation_sentences])\n",
    "y_train = np.array([sent2labels(s) for s in train_sentences])\n",
    "y_test = np.array([sent2labels(s) for s in validation_sentences])\n",
    "\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(crf_metrics.flat_f1_score, average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 42.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=CRF(algorithm='lbfgs',\n",
       "                                 all_possible_transitions=True,\n",
       "                                 keep_tempfiles=None, max_iterations=100),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7faecb299f40>,\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7faeb81fc100>},\n",
       "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=['B-class', 'I-class', 'B-attr', 'I-attr']),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-class      0.632     0.279     0.387       215\n",
      "     I-class      0.560     0.165     0.255        85\n",
      "      B-attr      0.667     0.300     0.414       140\n",
      "      I-attr      0.754     0.316     0.446       136\n",
      "\n",
      "   micro avg      0.662     0.276     0.390       576\n",
      "   macro avg      0.653     0.265     0.375       576\n",
      "weighted avg      0.659     0.276     0.388       576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass labels=['B-class', 'I-class', 'B-attr', 'I-attr'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "y_pred = rs.predict(X_test)\n",
    "print(crf_metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default model + class/attribute ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-100-edbbd5becca3>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train = np.array([sent2features(s, ratio = True) for s in train_sentences])\n",
      "<ipython-input-100-edbbd5becca3>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test = np.array([sent2features(s, ratio = True) for s in validation_sentences])\n",
      "<ipython-input-100-edbbd5becca3>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_train = np.array([sent2labels(s) for s in train_sentences])\n",
      "<ipython-input-100-edbbd5becca3>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_test = np.array([sent2labels(s) for s in validation_sentences])\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([sent2features(s, ratio = True) for s in train_sentences])\n",
    "X_test = np.array([sent2features(s, ratio = True) for s in validation_sentences])\n",
    "y_train = np.array([sent2labels(s) for s in train_sentences])\n",
    "y_test = np.array([sent2labels(s) for s in validation_sentences])\n",
    "\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(crf_metrics.flat_f1_score, average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:209: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  warnings.warn('From version 0.24, get_params will raise an '\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   45.7s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=CRF(algorithm='lbfgs',\n",
       "                                 all_possible_transitions=True,\n",
       "                                 keep_tempfiles=None, max_iterations=100),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc5e111ebe0>,\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc692e8e670>},\n",
       "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=['B-class', 'I-class', 'B-attr', 'I-attr']),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-class      0.623     0.307     0.411       215\n",
      "     I-class      0.255     0.153     0.191        85\n",
      "      B-attr      0.684     0.186     0.292       140\n",
      "      I-attr      0.821     0.169     0.280       136\n",
      "\n",
      "   micro avg      0.574     0.222     0.320       576\n",
      "   macro avg      0.596     0.204     0.294       576\n",
      "weighted avg      0.630     0.222     0.319       576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass labels=['B-class', 'I-class', 'B-attr', 'I-attr'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "y_pred = rs.predict(X_test)\n",
    "print(crf_metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All features together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-103-88db186df8e1>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train = np.array([sent2features(s, ratio = True, embedding = True) for s in train_sentences])\n",
      "<ipython-input-103-88db186df8e1>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_test = np.array([sent2features(s, ratio = True, embedding = True) for s in validation_sentences])\n",
      "<ipython-input-103-88db186df8e1>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_train = np.array([sent2labels(s) for s in train_sentences])\n",
      "<ipython-input-103-88db186df8e1>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  y_test = np.array([sent2labels(s) for s in validation_sentences])\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([sent2features(s, ratio = True, embedding = True) for s in train_sentences])\n",
    "X_test = np.array([sent2features(s, ratio = True, embedding = True) for s in validation_sentences])\n",
    "y_train = np.array([sent2labels(s) for s in train_sentences])\n",
    "y_test = np.array([sent2labels(s) for s in validation_sentences])\n",
    "\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(crf_metrics.flat_f1_score, average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 42.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=CRF(algorithm='lbfgs',\n",
       "                                 all_possible_transitions=True,\n",
       "                                 keep_tempfiles=None, max_iterations=100),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'c1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc676d3ee80>,\n",
       "                                        'c2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc5f8b634c0>},\n",
       "                   scoring=make_scorer(flat_f1_score, average=weighted, labels=['B-class', 'I-class', 'B-attr', 'I-attr']),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-class      0.651     0.321     0.430       215\n",
      "     I-class      0.425     0.200     0.272        85\n",
      "      B-attr      0.795     0.221     0.346       140\n",
      "      I-attr      0.844     0.199     0.321       136\n",
      "\n",
      "   micro avg      0.664     0.250     0.363       576\n",
      "   macro avg      0.679     0.235     0.342       576\n",
      "weighted avg      0.698     0.250     0.361       576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rs.predict(X_test)\n",
    "print(crf_metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     B-class      0.623     0.307     0.411       215\n",
    "     I-class      0.255     0.153     0.191        85\n",
    "      B-attr      0.684     0.186     0.292       140\n",
    "      I-attr      0.821     0.169     0.280       136\n",
    "\n",
    "   micro avg      0.574     0.222     0.320       576\n",
    "   macro avg      0.596     0.204     0.294       576\n",
    "weighted avg      0.630     0.222     0.319       576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     B-class      0.632     0.279     0.387       215\n",
    "     I-class      0.560     0.165     0.255        85\n",
    "      B-attr      0.667     0.300     0.414       140\n",
    "      I-attr      0.754     0.316     0.446       136\n",
    "\n",
    "   micro avg      0.662     0.276     0.390       576\n",
    "   macro avg      0.653     0.265     0.375       576\n",
    "weighted avg      0.659     0.276     0.388       576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     B-class      0.628     0.274     0.382       215\n",
    "     I-class      0.591     0.153     0.243        85\n",
    "      B-attr      0.677     0.300     0.416       140\n",
    "      I-attr      0.730     0.338     0.462       136\n",
    "\n",
    "   micro avg      0.664     0.278     0.392       576\n",
    "   macro avg      0.657     0.266     0.376       576\n",
    "weighted avg      0.659     0.278     0.389       576\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rs, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
